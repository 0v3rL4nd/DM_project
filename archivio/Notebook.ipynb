{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Mining: Harry Potter Sorting Hat\n",
    "Studente: Aloisio Chiara Ludovica\n",
    "Matricola: 239648\n",
    "A/A: 2024/2025"
   ],
   "id": "3aaf3c5966875f2c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "5fbc4f633f96e919"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Setup\n",
    "Come prima cosa, assicuriamoci che il seguente notebook funzioni sia con python 2 che 3, importiamo alcuni moduli di utilità e prepariamo le funzioni per salvare le immagini"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#imports pandas\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "import os\n",
    "#import warnings and Repress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ndarray size changed\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\") #White Grid\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \"..\"\n",
    "CHAPTER_ID= \"Harry-Potter\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=400):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "def save_figure(figure, fig_id, tight_layout=False, fig_extension=\"png\", resolution=400):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    figure.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "#palette colori\n",
    "# Tavola colori personalizzata per ogni casata\n",
    "hue_palette = {\n",
    "    0: '#9C2A2A',  # Rosso Grifondoro\n",
    "    1: '#F1C232',  # Giallo Hufflepuff\n",
    "    2: '#000080',  # Blu Corvonero\n",
    "    3: '#1A7F3C'   # Verde Serpeverde\n",
    "}\n",
    "\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Hrule--> \"=====\"\n",
    "hrule = lambda x : \"=\"*x\n",
    "Hrule = lambda x,y: \"=\"*(x//2)+y+\"=\"*(x//2)"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "49c70d44d0445d63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Motivazione dello studio\n",
    "Harry Potter è una serie di romanzi fantasy scritta da J.K. Rowling che segue le avventure di un giovane mago, Harry, mentre frequenta la Scuola di Magia e Stregoneria di Hogwarts e affronta il potente mago oscuro Lord Voldemort."
   ],
   "id": "9c49f6e35f0cc9ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"https://cdn.wallpapersafari.com/39/28/s9IzxG.jpg\", width=800)\n"
   ],
   "id": "5585ca24a008e97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Come sceglie le casate il Cappello Parlante?\n",
    "Il Cappello Parlante è un cappello magico che smista gli studenti nelle quattro casate di Hogwarts: Grifondoro, Serpeverde, Corvonero e Tassorosso. Durante la Cerimonia di Smistamento, il cappello viene posto sulla testa dello studente e legge nella sua mente desideri, qualità e potenziale. In base a ciò che trova, decide la casata più adatta. Si basa principalmete su alcune caratteristiche più rilevanti quali, ad esempio l'eredità genetica dei genitori, il coraggio, l'inelligenza, la lealtà, l'ambizione, la conoscenza delle arti oscure, abilità el giocare a quidditch, abilità nei duelli e creatività."
   ],
   "id": "1c01b2db685b9bef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"https://th.bing.com/th/id/OIP.gfkCacIGJu_4w9Q08F8G9gHaFu?rs=1&pid=ImgDetMain\", width=800)\n"
   ],
   "id": "d85326229788bcdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "L'obiettivo del seguente studio sarà, dunque, dopo aver studiato il dataset, quello di predire la casata di uno studente della scuola di magia e stregoneria di Hogwarts attraverso modelli di multi classificazione.",
   "id": "fd3d18e1f45692e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "36cc87c447d987bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Pre processing\n",
    "In questa prima parta andiamo a caricare i dati che verranno sottoposti a delle prime analisi di tipo strutturale che necesariamente porteranno all'individuazione di alcune trasformazioni necessarie per il proseguo delle analisi."
   ],
   "id": "200e81fdb1323637"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../harry_potter_students.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df.columns)\n",
    "\n",
    "df.head\n",
    "print(df.shape)"
   ],
   "id": "5858b520939b3939",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vediamo le informazioni sul dataset",
   "id": "2db9c89cf6074ae5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.info()",
   "id": "26d747eca49fe838",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Il comando `df.info()` mostra che il DataFrame ha 20.000 righe e 10 colonne. Otto colonne contengono dati numerici (`float64`) come Bravery, Intelligence, ecc., mentre due sono di tipo `object` (probabilmente stringhe), come Blood Status e House.\n",
    "Tutte le colonne hanno valori mancanti, quindi sarà necessario gestire i `NaN`. La memoria usata è circa **1.5 MB**.\n",
    "Iniziamo dunque i primi lavori di trasformazione del dataset, gestendo i valori NaN e eventuali duplicati al fine di aiutare la valutazione dei vari algoritmi."
   ],
   "id": "6e5f3e2ebee3221"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Iniziamo eliminand i duplicati"
   ],
   "id": "bb99f8bd9117809e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "print(df.shape)"
   ],
   "id": "36d216fd2082cd89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Eliminiamo le colonne che no ci servono, nel nostro caso id:",
   "id": "46051b664d1e64ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Scrivere codice\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ],
   "id": "8e1b6702aa4255c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Andiamo ora a gestire i valori NaN:\n",
    "\n"
   ],
   "id": "7cf599196c0d746"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.isnull().sum()",
   "id": "28ad2984179d08fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Decido di voler predire i NaN usando il modello KNN imputer, ma prima devo effettuare alcune conversioni, decidendo di effettuare label encoding sugli attributi \"Blood Status\", \"name\", \"surname\" e \"House\":\n",
   "id": "3ee3bede08eca66d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df['House'].unique())\n",
   "id": "4c15a0c728b19b6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Colonne da codificare\n",
    "columns_to_encode = ['name', 'surname', 'House', 'Blood Status']\n",
    "\n",
    "# Dizionario per salvare gli encoder\n",
    "label_encoders = {}\n",
    "\n",
    "for col in columns_to_encode:\n",
    "    # Trasforma in maiuscolo solo i valori non nulli\n",
    "    df[col] = df[col].apply(lambda x: x.upper() if pd.notnull(x) else x)\n",
    "\n",
    "    # Crea un encoder e applicalo solo ai valori non nulli\n",
    "    le = LabelEncoder()\n",
    "    non_null_mask = df[col].notnull()\n",
    "    df.loc[non_null_mask, col] = le.fit_transform(df.loc[non_null_mask, col])\n",
    "\n",
    "    # Salva l'encoder\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Ora df ha le colonne codificate, e i NaN sono ancora NaN\n",
    "df.head(60)\n",
    "\n"
   ],
   "id": "5a1977ebbcd1f415",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "encoder = label_encoders['House']\n",
    "encoder1 = label_encoders['Blood Status']\n",
    "encoder2 = label_encoders['name']\n",
    "encoder3 = label_encoders['surname']\n",
    "\n",
    "#visulizziamo il label encoding appena effettuato\n",
    "for i, label in enumerate(encoder.classes_):\n",
    "    print(f\"{i} → {label}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "for i, label in enumerate(encoder1.classes_):\n",
    "    print(f\"{i} → {label}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "for i, label in enumerate(encoder2.classes_):\n",
    "    print(f\"{i} → {label}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "for i, label in enumerate(encoder3.classes_):\n",
    "    print(f\"{i} → {label}\")"
   ],
   "id": "1b4d1bf8237c17ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Colonne categoriali da convertire in interi dopo l'imputazione\n",
    "categorical_columns = ['name', 'surname', 'House', 'Blood Status']\n",
    "\n",
    "# Applica KNNImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=2)\n",
    "df = pd.DataFrame(knn_imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Arrotonda e converte in interi solo le colonne categoriali\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].round().astype(int)\n",
    "\n",
    "# Visualizza il risultato\n",
    "print(df)\n"
   ],
   "id": "dd757cadb51a75a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ho sovrascritto il dataset con i miei valori aggiornati. Infatti:",
   "id": "3442c57998b967a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.isnull().sum()",
   "id": "41780848c06390b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ora effettivamente non ho più valori null.",
   "id": "7918f64c8f6410d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "2f210fc2d05a3be7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualizazion\n",
   "id": "88533e0a303b1311"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Pairplot del dataset (mostra scatter plot e distribuzioni per ogni variabile)\n",
    "sns.pairplot(df)\n",
    "\n",
    "# Mostrare il grafico\n",
    "plt.show()\n"
   ],
   "id": "5c0c92ca173da76c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Analizzare la relazione tra abilità e casata\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pairplot delle abilità colorato per House\n",
    "sns.pairplot(\n",
    "    df,\n",
    "    vars=['Bravery', 'Intelligence', 'Loyalty', 'Ambition'],\n",
    "    hue='House',\n",
    "    palette=hue_palette,\n",
    "    corner=True\n",
    ")\n",
    "plt.suptitle(\"Bravery vs Intelligence vs Loyalty vs Ambition\", y=1.02)\n",
    "plt.show()\n"
   ],
   "id": "d676e609fa159c09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Analizzare la relazione tra capacità e casate\n",
    "sns.pairplot(\n",
    "    df,\n",
    "    vars=['Dark Arts Knowledge', 'Dueling Skills', 'Quidditch Skills'],\n",
    "    hue='House',\n",
    "    palette=hue_palette,\n",
    "    corner=True\n",
    ")\n",
    "plt.suptitle(\"Dark Arts / Dueling / Quidditch vs House\", y=1.02)\n",
    "plt.show()\n"
   ],
   "id": "a402d9f05ba65b8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.pairplot(\n",
    "    df,\n",
    "    vars=['Creativity', 'Intelligence', 'age'],\n",
    "    hue='House',\n",
    "    palette=hue_palette,\n",
    "    corner=True\n",
    ")\n",
    "plt.suptitle(\"Creativity, Intelligence e Age in relazione alla House\", y=1.02)\n",
    "plt.show()\n"
   ],
   "id": "9aa0d5e97324df8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "selected_features = [\n",
    "    'Bravery', 'Intelligence', 'Loyalty', 'Ambition',\n",
    "    'Dark Arts Knowledge', 'Dueling Skills',\n",
    "    'Quidditch Skills', 'Creativity', 'age'\n",
    "]\n",
    "\n",
    "sns.pairplot(df, vars=selected_features, hue='House', palette=hue_palette, corner=True, plot_kws={'alpha': 0.6, 's': 40})\n",
    "plt.suptitle(\"Panoramica abilità e età per House\", y=1.02)\n",
    "plt.show()\n"
   ],
   "id": "4f947f0a65cc1e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Calcolare la matrice di correlazione\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Creare una heatmap della matrice di correlazione\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "\n",
    "# Mostrare il grafico\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ],
   "id": "e01a3d99a59592a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "84089b7ce31253e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Transformation",
   "id": "3469e3e047cfda22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dopo aver determinato gli attributi da usare nel processo di regressione, si provvede a preparare i dati da passare agli algoritmi di machine learning. In particolare le trasformazioni che seguiranno non rientrano nel data cleaning, che invece è stato effettuato a monte, quanto principalmente la discretizzazione, l'omogeneizzazione e la codifica dei dati.",
   "id": "f92507315e062df2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.name.unique()\n",
    "\n",
    "df['name'].value_counts().head()"
   ],
   "id": "c231571977ecfef3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler_std = StandardScaler()\n",
    "df_scaled_std = pd.DataFrame(scaler_std.fit_transform(df), columns=df.columns)\n",
    "\n",
    "scaler_minmax = MinMaxScaler()\n",
    "df_scaled_minmax = pd.DataFrame(scaler_minmax.fit_transform(df), columns=df.columns)\n"
   ],
   "id": "a3db2c565584fd25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Confronto distribuzioni dopo scaling\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.kdeplot(df_scaled_std[\"Bravery\"], label=\"Standard Scaled\")\n",
    "sns.kdeplot(df_scaled_minmax[\"Bravery\"], label=\"Min-Max Scaled\")\n",
    "plt.title(\"Distribuzione della feature 'Bravery' dopo scaling\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "39e2d0c3d2244b0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)  # Conserva il 95% della varianza\n",
    "df_pca = pd.DataFrame(pca.fit_transform(df_scaled_std))\n"
   ],
   "id": "69280e25f79de344",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Visualizzazione PCA\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=df_pca[0], y=df_pca[1])\n",
    "plt.title(\"PCA - Prima e Seconda Componente\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()\n"
   ],
   "id": "ec923649ec91fae7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_engineered = df.copy()\n",
    "df_engineered[\"Courage\"] = df_engineered[\"Bravery\"] + df_engineered[\"Loyalty\"]\n",
    "df_engineered[\"Magic Index\"] = df_engineered[[\"Dark Arts Knowledge\", \"Dueling Skills\", \"Quidditch Skills\"]].mean(axis=1)\n"
   ],
   "id": "2428cbf166506623",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#visualizzazione feature ingegnerizzate\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_engineered[\"Courage\"], bins=30, kde=True, color='orange')\n",
    "plt.title(\"Distribuzione della nuova feature 'Courage'\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_engineered[\"Magic Index\"], bins=30, kde=True, color='purple')\n",
    "plt.title(\"Distribuzione della nuova feature 'Magic Index'\")\n",
    "plt.show()"
   ],
   "id": "49588691f09675b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df_log_transformed = df.copy()\n",
    "for col in df_log_transformed.columns:\n",
    "    df_log_transformed[col] = np.log1p(df_log_transformed[col])  # log(1 + x)\n"
   ],
   "id": "2017ac69b82193ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Confronto distribuzione originale vs log-transformed\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sns.histplot(df[\"Dark Arts Knowledge\"], bins=30, kde=True, ax=axes[0])\n",
    "axes[0].set_title(\"Originale - Dark Arts Knowledge\")\n",
    "\n",
    "sns.histplot(df_log_transformed[\"Dark Arts Knowledge\"], bins=30, kde=True, ax=axes[1], color='green')\n",
    "axes[1].set_title(\"Log Trasformata - Dark Arts Knowledge\")\n",
    "plt.show()\n"
   ],
   "id": "a9fea92eb4d556c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "if \"age\" in df.columns:\n",
    "    discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "    df_binned = df.copy()\n",
    "    df_binned[\"age_group\"] = discretizer.fit_transform(df_binned[[\"age\"]])\n"
   ],
   "id": "d63f5a222b9e5110",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Visualizzazione gruppi di età\n",
    "sns.countplot(x=\"age_group\", data=df_binned)\n",
    "plt.title(\"Distribuzione delle età binned\")\n",
    "plt.xlabel(\"Gruppo di Età (0 = giovane, 2 = adulto)\")\n",
    "plt.ylabel(\"Conteggio\")\n",
    "plt.show()"
   ],
   "id": "a3be3d28b10c1c5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Prima di iniziare ad addestrare gli algoritmi, andiamo ad effettuare il drop della colonna che vogliamo andare a predirre, ovvero 'House'",
   "id": "13c692e628505c6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Feature/target split\n",
    "X = df.drop(\"House\", axis=1)\n",
    "y = df[\"House\"]\n",
    "\n",
    "# Binarizza il target per AUC multiclass\n",
    "classes = y.unique()\n",
    "y_bin = label_binarize(y, classes=classes)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test, y_train_bin, y_test_bin = train_test_split(\n",
    "    X, y, y_bin, test_size=0.2, random_state=42)\n",
    "\n"
   ],
   "id": "665338ea5c470b30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ensamble",
   "id": "16a89dc8edd16e16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ],
   "id": "fd11623917105189",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RandomForest",
   "id": "f3430abf3158568c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_prob_rf = rf.predict_proba(X_test)\n",
    "auc_rf = roc_auc_score(y_test_bin, y_prob_rf, multi_class=\"ovr\", average=\"macro\")\n",
    "print(\"Random Forest AUC:\", auc_rf)"
   ],
   "id": "9ffcbf9bfe7c1c5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## AdaBoost",
   "id": "bb5639a50a0567aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ada = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ada.fit(X_train, y_train)\n",
    "y_prob_ada = ada.predict_proba(X_test)\n",
    "auc_ada = roc_auc_score(y_test_bin, y_prob_ada, multi_class=\"ovr\", average=\"macro\")\n",
    "print(\"AdaBoost AUC:\", auc_ada)"
   ],
   "id": "de7364ec53fa6c78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Bagging",
   "id": "71f4b3ba1518b07e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bag = BaggingClassifier(n_estimators=100, random_state=42)\n",
    "bag.fit(X_train, y_train)\n",
    "y_prob_bag = bag.predict_proba(X_test)\n",
    "auc_bag = roc_auc_score(y_test_bin, y_prob_bag, multi_class=\"ovr\", average=\"macro\")\n",
    "print(\"Bagging AUC:\", auc_bag)"
   ],
   "id": "99157e2dae199fee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Algoritmi a confronto:"
   ],
   "id": "f3fdcc621af85a11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "auc_scores = {\n",
    "    \"Random Forest\": auc_rf,\n",
    "    \"AdaBoost\": auc_ada,\n",
    "    \"Bagging\": auc_bag\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x=list(auc_scores.keys()), y=list(auc_scores.values()), palette=\"viridis\")\n",
    "plt.title(\"Confronto AUC tra modelli ensemble\")\n",
    "plt.ylabel(\"Macro AUC\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ],
   "id": "6c9661c3fe4038d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Accuracy\n",
    "acc_rf = accuracy_score(y_test, rf.predict(X_test))\n",
    "acc_ada = accuracy_score(y_test, ada.predict(X_test))\n",
    "acc_bag = accuracy_score(y_test, bag.predict(X_test))\n",
    "\n",
    "print(f\"Accuracy Random Forest: {acc_rf:.3f}\")\n",
    "print(f\"Accuracy AdaBoost: {acc_ada:.3f}\")\n",
    "print(f\"Accuracy Bagging: {acc_bag:.3f}\")\n"
   ],
   "id": "6de3fba38cf1eab8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Random Forest\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5]\n",
    "}\n",
    "gs_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "gs_rf.fit(X_train, y_train)\n",
    "print(\"Best RF:\", gs_rf.best_params_, \"Acc:\", gs_rf.best_score_)\n",
    "\n",
    "# AdaBoost\n",
    "param_grid_ada = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"learning_rate\": [0.5, 1.0, 1.5]\n",
    "}\n",
    "gs_ada = GridSearchCV(AdaBoostClassifier(random_state=42), param_grid_ada, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "gs_ada.fit(X_train, y_train)\n",
    "print(\"Best AdaBoost:\", gs_ada.best_params_, \"Acc:\", gs_ada.best_score_)\n",
    "\n",
    "# Bagging\n",
    "param_grid_bag = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_samples\": [0.5, 0.7, 1.0]\n",
    "}\n",
    "gs_bag = GridSearchCV(BaggingClassifier(random_state=42), param_grid_bag, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "gs_bag.fit(X_train, y_train)\n",
    "print(\"Best Bagging:\", gs_bag.best_params_, \"Acc:\", gs_bag.best_score_)\n"
   ],
   "id": "1d905dc022e3addd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "acc_scores = {\n",
    "    \"Random Forest\": acc_rf,\n",
    "    \"AdaBoost\": acc_ada,\n",
    "    \"Bagging\": acc_bag\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x=list(acc_scores.keys()), y=list(acc_scores.values()), palette=\"mako\")\n",
    "plt.title(\"Confronto Accuracy tra modelli\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ],
   "id": "7c94c0b7c0812a6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Lista di modelli e nomi\n",
    "models = [\n",
    "    (\"Random Forest\", rf),\n",
    "    (\"AdaBoost\", ada),\n",
    "    (\"Bagging\", bag)\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "for i, (name, model) in enumerate(models):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    disp.plot(ax=plt.gca(), cmap=\"Blues\", colorbar=False)\n",
    "    plt.title(name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "ea3d537117719a6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Come possiamo notare da queste confusion matrix, questi algoritmi non lavorano molto bene. Ciò accade perchè non è stato eseguito il tuning degli iperparameter. Procediamo dunque a fare ciò e facciamo lavorare nuovamente gli algoritmi",
   "id": "a14f7e04f5401066"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay,\n",
    "                             precision_score, recall_score, f1_score, accuracy_score, classification_report,\n",
    "                             roc_curve, auc, RocCurveDisplay)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "# Dizionari dei parametri per ciascun classificatore\n",
    "param_grids = {\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [None, 10],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"]\n",
    "    },\n",
    "    \"AdaBoost\": {\n",
    "        \"n_estimators\": [50, 100],\n",
    "        \"learning_rate\": [0.5, 1.0]\n",
    "    },\n",
    "    \"Bagging\": {\n",
    "        \"n_estimators\": [10, 50],\n",
    "        \"max_samples\": [0.5, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Classificatori\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Bagging\": BaggingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Per salvare i migliori modelli e le metriche\n",
    "best_models = {}\n",
    "metrics_summary = []\n",
    "\n",
    "# Grid Search e valutazione\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"🔍 Grid Search per {name}...\")\n",
    "    grid = GridSearchCV(clf, param_grids[name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "\n",
    "    print(f\"✅ Migliori parametri per {name}: {grid.best_params_}\")\n",
    "    print(f\"🎯 Accuracy media cross-val: {grid.best_score_:.4f}\")\n",
    "\n",
    "    # Predizione e metriche\n",
    "    y_pred = grid.best_estimator_.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='macro')\n",
    "    rec = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print(f\"📊 Confusion Matrix per {name}:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f\"{name} - Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Report\n",
    "    print(f\"📋 Classification Report per {name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # ROC Curve e AUC\n",
    "    print(f\"📈 ROC Curve e AUC per {name}:\")\n",
    "    if len(np.unique(y_test)) == 2:\n",
    "        # Caso binario\n",
    "        y_score = grid.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f\"{name} - ROC Curve\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        # Caso multi-classe\n",
    "        y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
    "        y_score = grid.best_estimator_.predict_proba(X_test)\n",
    "        n_classes = y_test_bin.shape[1]\n",
    "\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Media macro dell'AUC\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(n_classes):\n",
    "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "        mean_tpr /= n_classes\n",
    "        macro_auc = auc(all_fpr, mean_tpr)\n",
    "\n",
    "        plt.figure()\n",
    "        for i in range(n_classes):\n",
    "            plt.plot(fpr[i], tpr[i], lw=2, label=f'Classe {i} (AUC = {roc_auc[i]:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f\"{name} - ROC Curve Multiclasse (macro AUC = {macro_auc:.2f})\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "    # Salvataggio metriche\n",
    "    metrics_summary.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision (macro)\": prec,\n",
    "        \"Recall (macro)\": rec,\n",
    "        \"F1-score (macro)\": f1\n",
    "    })\n",
    "\n",
    "# Mostriamo la classifica finale\n",
    "df_metrics = pd.DataFrame(metrics_summary)\n",
    "df_sorted = df_metrics.sort_values(by=\"F1-score (macro)\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n🏆 Classifica finale dei modelli (ordinata per F1-score macro):\")\n",
    "display(df_sorted)\n"
   ],
   "id": "99d7601be7b64374",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# aggiungere confronto degli algoritmi prima e dopo del preprocessing",
   "id": "a8b5f46d73d3f2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "971c5cbbf7ab6060"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Regression",
   "id": "fbe509e772148fba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
