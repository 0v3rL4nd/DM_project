{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Mining: Harry Potter Sorting Hat\n",
    "Studente: Aloisio Chiara Ludovica\n",
    "Matricola: 239648\n",
    "A/A: 2024/2025"
   ],
   "id": "3aaf3c5966875f2c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "5fbc4f633f96e919"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Setup\n",
    "Come prima cosa, assicuriamoci che il seguente notebook funzioni sia con python 2 che 3, importiamo alcuni moduli di utilit√† e prepariamo le funzioni per salvare le immagini"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Python ‚â•3.5 is required\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ‚â•0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#imports pandas\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "import os\n",
    "#import warnings and Repress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ndarray size changed\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\") #White Grid\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \"..\"\n",
    "CHAPTER_ID= \"Harry-Potter\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=400):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "def save_figure(figure, fig_id, tight_layout=False, fig_extension=\"png\", resolution=400):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    figure.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "#palette colori\n",
    "# Tavola colori personalizzata per ogni casata\n",
    "hue_palette = {\n",
    "    0: '#9C2A2A',  # Rosso Grifondoro\n",
    "    1: '#F1C232',  # Giallo Hufflepuff\n",
    "    2: '#000080',  # Blu Corvonero\n",
    "    3: '#1A7F3C'   # Verde Serpeverde\n",
    "}\n",
    "\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Hrule--> \"=====\"\n",
    "hrule = lambda x : \"=\"*x\n",
    "Hrule = lambda x,y: \"=\"*(x//2)+y+\"=\"*(x//2)"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "49c70d44d0445d63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Motivazione dello studio\n",
    "Harry Potter √® una serie di romanzi fantasy scritta da J.K. Rowling che segue le avventure di un giovane mago, Harry, mentre frequenta la Scuola di Magia e Stregoneria di Hogwarts e affronta il potente mago oscuro Lord Voldemort."
   ],
   "id": "9c49f6e35f0cc9ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"https://cdn.wallpapersafari.com/39/28/s9IzxG.jpg\", width=800)\n"
   ],
   "id": "5585ca24a008e97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Come sceglie le casate il Cappello Parlante?\n",
    "Il Cappello Parlante √® un cappello magico che smista gli studenti nelle quattro casate di Hogwarts: Grifondoro, Serpeverde, Corvonero e Tassorosso. Durante la Cerimonia di Smistamento, il cappello viene posto sulla testa dello studente e legge nella sua mente desideri, qualit√† e potenziale. In base a ci√≤ che trova, decide la casata pi√π adatta. Si basa principalmete su alcune caratteristiche pi√π rilevanti quali, ad esempio l'eredit√† genetica dei genitori, il coraggio, l'inelligenza, la lealt√†, l'ambizione, la conoscenza delle arti oscure, abilit√† el giocare a quidditch, abilit√† nei duelli e creativit√†."
   ],
   "id": "1c01b2db685b9bef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"https://th.bing.com/th/id/OIP.gfkCacIGJu_4w9Q08F8G9gHaFu?rs=1&pid=ImgDetMain\", width=800)\n"
   ],
   "id": "d85326229788bcdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "L'obiettivo del seguente studio sar√†, dunque, dopo aver studiato il dataset, quello di predire la casata di uno studente della scuola di magia e stregoneria di Hogwarts attraverso modelli di multi classificazione.",
   "id": "fd3d18e1f45692e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "36cc87c447d987bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Pre processing\n",
    "In questa prima parta andiamo a caricare i dati che verranno sottoposti a delle prime analisi di tipo strutturale che necesariamente porteranno all'individuazione di alcune trasformazioni necessarie per il proseguo delle analisi."
   ],
   "id": "200e81fdb1323637"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../harry_potter_students.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df.columns)\n",
    "\n",
    "df.head\n",
    "print(df.shape)"
   ],
   "id": "5858b520939b3939",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vediamo le informazioni sul dataset",
   "id": "2db9c89cf6074ae5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.info()",
   "id": "26d747eca49fe838",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Il comando `df.info()` mostra che il DataFrame ha 20.000 righe e 10 colonne. Otto colonne contengono dati numerici (`float64`) come Bravery, Intelligence, ecc., mentre due sono di tipo `object` (probabilmente stringhe), come Blood Status e House.\n",
    "Tutte le colonne hanno valori mancanti, quindi sar√† necessario gestire i `NaN`. La memoria usata √® circa **1.5 MB**.\n",
    "Iniziamo dunque i primi lavori di trasformazione del dataset, gestendo i valori NaN e eventuali duplicati al fine di aiutare la valutazione dei vari algoritmi."
   ],
   "id": "6e5f3e2ebee3221"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Iniziamo eliminand i duplicati"
   ],
   "id": "bb99f8bd9117809e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "print(df.shape)"
   ],
   "id": "36d216fd2082cd89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Eliminiamo le colonne che no ci servono, nel nostro caso id:",
   "id": "46051b664d1e64ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Scrivere codice\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ],
   "id": "8e1b6702aa4255c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Andiamo ora a gestire i valori NaN:\n",
    "\n"
   ],
   "id": "7cf599196c0d746"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.isnull().sum()",
   "id": "28ad2984179d08fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Decido di voler predire i NaN usando il modello KNN imputer, ma prima devo effettuare alcune conversioni, decidendo di effettuare label encoding sugli attributi \"Blood Status\", \"name\", \"surname\" e \"House\":\n",
   "id": "3ee3bede08eca66d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df['House'].unique())\n",
   "id": "4c15a0c728b19b6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Colonne da codificare\n",
    "columns_to_encode = ['name', 'surname', 'House', 'Blood Status']\n",
    "\n",
    "# Dizionario per salvare gli encoder\n",
    "label_encoders = {}\n",
    "\n",
    "for col in columns_to_encode:\n",
    "    # Trasforma in maiuscolo solo i valori non nulli\n",
    "    df[col] = df[col].apply(lambda x: x.upper() if pd.notnull(x) else x)\n",
    "\n",
    "    # Crea un encoder e applicalo solo ai valori non nulli\n",
    "    le = LabelEncoder()\n",
    "    non_null_mask = df[col].notnull()\n",
    "    df.loc[non_null_mask, col] = le.fit_transform(df.loc[non_null_mask, col])\n",
    "\n",
    "    # Salva l'encoder\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Ora df ha le colonne codificate, e i NaN sono ancora NaN\n",
    "df.head(60)\n",
    "\n"
   ],
   "id": "5a1977ebbcd1f415",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "encoder = label_encoders['House']\n",
    "encoder1 = label_encoders['Blood Status']\n",
    "encoder2 = label_encoders['name']\n",
    "encoder3 = label_encoders['surname']\n",
    "\n",
    "#visulizziamo il label encoding appena effettuato\n",
    "for i, label in enumerate(encoder.classes_):\n",
    "    print(f\"{i} ‚Üí {label}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "for i, label in enumerate(encoder1.classes_):\n",
    "    print(f\"{i} ‚Üí {label}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "for i, label in enumerate(encoder2.classes_):\n",
    "    print(f\"{i} ‚Üí {label}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "for i, label in enumerate(encoder3.classes_):\n",
    "    print(f\"{i} ‚Üí {label}\")"
   ],
   "id": "1b4d1bf8237c17ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Colonne categoriali da convertire in interi dopo l'imputazione\n",
    "categorical_columns = ['name', 'surname', 'House', 'Blood Status']\n",
    "\n",
    "# Applica KNNImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=2)\n",
    "df = pd.DataFrame(knn_imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Arrotonda e converte in interi solo le colonne categoriali\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].round().astype(int)\n",
    "\n",
    "# Visualizza il risultato\n",
    "print(df)\n"
   ],
   "id": "dd757cadb51a75a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ho sovrascritto il dataset con i miei valori aggiornati. Infatti:",
   "id": "3442c57998b967a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.isnull().sum()",
   "id": "41780848c06390b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ora effettivamente non ho pi√π valori null.",
   "id": "7918f64c8f6410d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "2f210fc2d05a3be7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualizazion\n",
   "id": "88533e0a303b1311"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Pairplot del dataset (mostra scatter plot e distribuzioni per ogni variabile)\n",
    "sns.pairplot(df)\n",
    "\n",
    "# Mostrare il grafico\n",
    "plt.show()\n"
   ],
   "id": "5c0c92ca173da76c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Analizzare la relazione tra abilit√† e casata\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pairplot delle abilit√† colorato per House\n",
    "sns.pairplot(\n",
    "    df,\n",
    "    vars=['Bravery', 'Intelligence', 'Loyalty', 'Ambition'],\n",
    "    hue='House',\n",
    "    palette=hue_palette,\n",
    "    corner=True\n",
    ")\n",
    "plt.suptitle(\"Bravery vs Intelligence vs Loyalty vs Ambition\", y=1.02)\n",
    "plt.show()\n"
   ],
   "id": "d676e609fa159c09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Analizzare la relazione tra capacit√† e casate\n",
    "sns.pairplot(\n",
    "    df,\n",
    "    vars=['Dark Arts Knowledge', 'Dueling Skills', 'Quidditch Skills'],\n",
    "    hue='House',\n",
    "    palette=hue_palette,\n",
    "    corner=True\n",
    ")\n",
    "plt.suptitle(\"Dark Arts / Dueling / Quidditch vs House\", y=1.02)\n",
    "plt.show()\n"
   ],
   "id": "a402d9f05ba65b8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.pairplot(\n",
    "    df,\n",
    "    vars=['Creativity', 'Intelligence', 'age'],\n",
    "    hue='House',\n",
    "    palette=hue_palette,\n",
    "    corner=True\n",
    ")\n",
    "plt.suptitle(\"Creativity, Intelligence e Age in relazione alla House\", y=1.02)\n",
    "plt.show()\n"
   ],
   "id": "9aa0d5e97324df8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "selected_features = [\n",
    "    'Bravery', 'Intelligence', 'Loyalty', 'Ambition',\n",
    "    'Dark Arts Knowledge', 'Dueling Skills',\n",
    "    'Quidditch Skills', 'Creativity', 'age'\n",
    "]\n",
    "\n",
    "sns.pairplot(df, vars=selected_features, hue='House', palette=hue_palette, corner=True, plot_kws={'alpha': 0.6, 's': 40})\n",
    "plt.suptitle(\"Panoramica abilit√† e et√† per House\", y=1.02)\n",
    "plt.show()\n"
   ],
   "id": "4f947f0a65cc1e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Calcolare la matrice di correlazione\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Creare una heatmap della matrice di correlazione\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "\n",
    "# Mostrare il grafico\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ],
   "id": "e01a3d99a59592a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "84089b7ce31253e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Transformation",
   "id": "3469e3e047cfda22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dopo aver determinato gli attributi da usare nel processo di regressione, si provvede a preparare i dati da passare agli algoritmi di machine learning. In particolare le trasformazioni che seguiranno non rientrano nel data cleaning, che invece √® stato effettuato a monte, quanto principalmente la discretizzazione, l'omogeneizzazione e la codifica dei dati.",
   "id": "f92507315e062df2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.name.unique()\n",
    "\n",
    "df['name'].value_counts().head()"
   ],
   "id": "c231571977ecfef3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler_std = StandardScaler()\n",
    "df_scaled_std = pd.DataFrame(scaler_std.fit_transform(df), columns=df.columns)\n",
    "\n",
    "scaler_minmax = MinMaxScaler()\n",
    "df_scaled_minmax = pd.DataFrame(scaler_minmax.fit_transform(df), columns=df.columns)\n"
   ],
   "id": "a3db2c565584fd25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Confronto distribuzioni dopo scaling\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.kdeplot(df_scaled_std[\"Bravery\"], label=\"Standard Scaled\")\n",
    "sns.kdeplot(df_scaled_minmax[\"Bravery\"], label=\"Min-Max Scaled\")\n",
    "plt.title(\"Distribuzione della feature 'Bravery' dopo scaling\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "39e2d0c3d2244b0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)  # Conserva il 95% della varianza\n",
    "df_pca = pd.DataFrame(pca.fit_transform(df_scaled_std))\n"
   ],
   "id": "69280e25f79de344",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Visualizzazione PCA\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=df_pca[0], y=df_pca[1])\n",
    "plt.title(\"PCA - Prima e Seconda Componente\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()\n"
   ],
   "id": "ec923649ec91fae7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_engineered = df.copy()\n",
    "df_engineered[\"Courage\"] = df_engineered[\"Bravery\"] + df_engineered[\"Loyalty\"]\n",
    "df_engineered[\"Magic Index\"] = df_engineered[[\"Dark Arts Knowledge\", \"Dueling Skills\", \"Quidditch Skills\"]].mean(axis=1)\n"
   ],
   "id": "2428cbf166506623",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#visualizzazione feature ingegnerizzate\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_engineered[\"Courage\"], bins=30, kde=True, color='orange')\n",
    "plt.title(\"Distribuzione della nuova feature 'Courage'\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_engineered[\"Magic Index\"], bins=30, kde=True, color='purple')\n",
    "plt.title(\"Distribuzione della nuova feature 'Magic Index'\")\n",
    "plt.show()"
   ],
   "id": "49588691f09675b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df_log_transformed = df.copy()\n",
    "for col in df_log_transformed.columns:\n",
    "    df_log_transformed[col] = np.log1p(df_log_transformed[col])  # log(1 + x)\n"
   ],
   "id": "2017ac69b82193ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Confronto distribuzione originale vs log-transformed\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sns.histplot(df[\"Dark Arts Knowledge\"], bins=30, kde=True, ax=axes[0])\n",
    "axes[0].set_title(\"Originale - Dark Arts Knowledge\")\n",
    "\n",
    "sns.histplot(df_log_transformed[\"Dark Arts Knowledge\"], bins=30, kde=True, ax=axes[1], color='green')\n",
    "axes[1].set_title(\"Log Trasformata - Dark Arts Knowledge\")\n",
    "plt.show()\n"
   ],
   "id": "a9fea92eb4d556c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "if \"age\" in df.columns:\n",
    "    discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "    df_binned = df.copy()\n",
    "    df_binned[\"age_group\"] = discretizer.fit_transform(df_binned[[\"age\"]])\n"
   ],
   "id": "d63f5a222b9e5110",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Visualizzazione gruppi di et√†\n",
    "sns.countplot(x=\"age_group\", data=df_binned)\n",
    "plt.title(\"Distribuzione delle et√† binned\")\n",
    "plt.xlabel(\"Gruppo di Et√† (0 = giovane, 2 = adulto)\")\n",
    "plt.ylabel(\"Conteggio\")\n",
    "plt.show()"
   ],
   "id": "a3be3d28b10c1c5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Prima di iniziare ad addestrare gli algoritmi, andiamo ad effettuare il drop della colonna che vogliamo andare a predirre, ovvero 'House'",
   "id": "13c692e628505c6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Feature/target split\n",
    "X = df.drop(\"House\", axis=1)\n",
    "y = df[\"House\"]\n",
    "\n",
    "# Binarizza il target per AUC multiclass\n",
    "classes = y.unique()\n",
    "y_bin = label_binarize(y, classes=classes)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test, y_train_bin, y_test_bin = train_test_split(\n",
    "    X, y, y_bin, test_size=0.2, random_state=42)\n",
    "\n"
   ],
   "id": "665338ea5c470b30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ensamble",
   "id": "16a89dc8edd16e16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ],
   "id": "fd11623917105189",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RandomForest",
   "id": "f3430abf3158568c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_prob_rf = rf.predict_proba(X_test)\n",
    "auc_rf = roc_auc_score(y_test_bin, y_prob_rf, multi_class=\"ovr\", average=\"macro\")\n",
    "print(\"Random Forest AUC:\", auc_rf)"
   ],
   "id": "9ffcbf9bfe7c1c5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## AdaBoost",
   "id": "bb5639a50a0567aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ada = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ada.fit(X_train, y_train)\n",
    "y_prob_ada = ada.predict_proba(X_test)\n",
    "auc_ada = roc_auc_score(y_test_bin, y_prob_ada, multi_class=\"ovr\", average=\"macro\")\n",
    "print(\"AdaBoost AUC:\", auc_ada)"
   ],
   "id": "de7364ec53fa6c78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Bagging",
   "id": "71f4b3ba1518b07e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bag = BaggingClassifier(n_estimators=100, random_state=42)\n",
    "bag.fit(X_train, y_train)\n",
    "y_prob_bag = bag.predict_proba(X_test)\n",
    "auc_bag = roc_auc_score(y_test_bin, y_prob_bag, multi_class=\"ovr\", average=\"macro\")\n",
    "print(\"Bagging AUC:\", auc_bag)"
   ],
   "id": "99157e2dae199fee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Algoritmi a confronto:"
   ],
   "id": "f3fdcc621af85a11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "auc_scores = {\n",
    "    \"Random Forest\": auc_rf,\n",
    "    \"AdaBoost\": auc_ada,\n",
    "    \"Bagging\": auc_bag\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x=list(auc_scores.keys()), y=list(auc_scores.values()), palette=\"viridis\")\n",
    "plt.title(\"Confronto AUC tra modelli ensemble\")\n",
    "plt.ylabel(\"Macro AUC\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ],
   "id": "6c9661c3fe4038d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Accuracy\n",
    "acc_rf = accuracy_score(y_test, rf.predict(X_test))\n",
    "acc_ada = accuracy_score(y_test, ada.predict(X_test))\n",
    "acc_bag = accuracy_score(y_test, bag.predict(X_test))\n",
    "\n",
    "print(f\"Accuracy Random Forest: {acc_rf:.3f}\")\n",
    "print(f\"Accuracy AdaBoost: {acc_ada:.3f}\")\n",
    "print(f\"Accuracy Bagging: {acc_bag:.3f}\")\n"
   ],
   "id": "6de3fba38cf1eab8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Random Forest\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5]\n",
    "}\n",
    "gs_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "gs_rf.fit(X_train, y_train)\n",
    "print(\"Best RF:\", gs_rf.best_params_, \"Acc:\", gs_rf.best_score_)\n",
    "\n",
    "# AdaBoost\n",
    "param_grid_ada = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"learning_rate\": [0.5, 1.0, 1.5]\n",
    "}\n",
    "gs_ada = GridSearchCV(AdaBoostClassifier(random_state=42), param_grid_ada, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "gs_ada.fit(X_train, y_train)\n",
    "print(\"Best AdaBoost:\", gs_ada.best_params_, \"Acc:\", gs_ada.best_score_)\n",
    "\n",
    "# Bagging\n",
    "param_grid_bag = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_samples\": [0.5, 0.7, 1.0]\n",
    "}\n",
    "gs_bag = GridSearchCV(BaggingClassifier(random_state=42), param_grid_bag, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "gs_bag.fit(X_train, y_train)\n",
    "print(\"Best Bagging:\", gs_bag.best_params_, \"Acc:\", gs_bag.best_score_)\n"
   ],
   "id": "1d905dc022e3addd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "acc_scores = {\n",
    "    \"Random Forest\": acc_rf,\n",
    "    \"AdaBoost\": acc_ada,\n",
    "    \"Bagging\": acc_bag\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x=list(acc_scores.keys()), y=list(acc_scores.values()), palette=\"mako\")\n",
    "plt.title(\"Confronto Accuracy tra modelli\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ],
   "id": "7c94c0b7c0812a6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Lista di modelli e nomi\n",
    "models = [\n",
    "    (\"Random Forest\", rf),\n",
    "    (\"AdaBoost\", ada),\n",
    "    (\"Bagging\", bag)\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "for i, (name, model) in enumerate(models):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    disp.plot(ax=plt.gca(), cmap=\"Blues\", colorbar=False)\n",
    "    plt.title(name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "ea3d537117719a6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Come possiamo notare da queste confusion matrix, questi algoritmi non lavorano molto bene. Ci√≤ accade perch√® non √® stato eseguito il tuning degli iperparameter. Procediamo dunque a fare ci√≤ e facciamo lavorare nuovamente gli algoritmi",
   "id": "a14f7e04f5401066"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay,\n",
    "                             precision_score, recall_score, f1_score, accuracy_score, classification_report,\n",
    "                             roc_curve, auc, RocCurveDisplay)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "# Dizionari dei parametri per ciascun classificatore\n",
    "param_grids = {\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [None, 10],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"]\n",
    "    },\n",
    "    \"AdaBoost\": {\n",
    "        \"n_estimators\": [50, 100],\n",
    "        \"learning_rate\": [0.5, 1.0]\n",
    "    },\n",
    "    \"Bagging\": {\n",
    "        \"n_estimators\": [10, 50],\n",
    "        \"max_samples\": [0.5, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Classificatori\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Bagging\": BaggingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Per salvare i migliori modelli e le metriche\n",
    "best_models = {}\n",
    "metrics_summary = []\n",
    "\n",
    "# Grid Search e valutazione\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"üîç Grid Search per {name}...\")\n",
    "    grid = GridSearchCV(clf, param_grids[name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "\n",
    "    print(f\"‚úÖ Migliori parametri per {name}: {grid.best_params_}\")\n",
    "    print(f\"üéØ Accuracy media cross-val: {grid.best_score_:.4f}\")\n",
    "\n",
    "    # Predizione e metriche\n",
    "    y_pred = grid.best_estimator_.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='macro')\n",
    "    rec = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print(f\"üìä Confusion Matrix per {name}:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f\"{name} - Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Report\n",
    "    print(f\"üìã Classification Report per {name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # ROC Curve e AUC\n",
    "    print(f\"üìà ROC Curve e AUC per {name}:\")\n",
    "    if len(np.unique(y_test)) == 2:\n",
    "        # Caso binario\n",
    "        y_score = grid.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f\"{name} - ROC Curve\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        # Caso multi-classe\n",
    "        y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
    "        y_score = grid.best_estimator_.predict_proba(X_test)\n",
    "        n_classes = y_test_bin.shape[1]\n",
    "\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Media macro dell'AUC\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(n_classes):\n",
    "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "        mean_tpr /= n_classes\n",
    "        macro_auc = auc(all_fpr, mean_tpr)\n",
    "\n",
    "        plt.figure()\n",
    "        for i in range(n_classes):\n",
    "            plt.plot(fpr[i], tpr[i], lw=2, label=f'Classe {i} (AUC = {roc_auc[i]:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f\"{name} - ROC Curve Multiclasse (macro AUC = {macro_auc:.2f})\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "    # Salvataggio metriche\n",
    "    metrics_summary.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision (macro)\": prec,\n",
    "        \"Recall (macro)\": rec,\n",
    "        \"F1-score (macro)\": f1\n",
    "    })\n",
    "\n",
    "# Mostriamo la classifica finale\n",
    "df_metrics = pd.DataFrame(metrics_summary)\n",
    "df_sorted = df_metrics.sort_values(by=\"F1-score (macro)\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nüèÜ Classifica finale dei modelli (ordinata per F1-score macro):\")\n",
    "display(df_sorted)\n"
   ],
   "id": "99d7601be7b64374",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# aggiungere confronto degli algoritmi prima e dopo del preprocessing",
   "id": "a8b5f46d73d3f2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "971c5cbbf7ab6060"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Regression",
   "id": "fbe509e772148fba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
